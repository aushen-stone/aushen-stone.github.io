#!/usr/bin/env python3
"""Prepare mapped product photos for web delivery.

Reads photo audit CSV rows with status=mapped, converts source files to WEBP,
emits deterministic filenames under public/product-photos, and generates
TypeScript image mapping data consumed by the app.
"""

from __future__ import annotations

import argparse
import csv
import json
import shutil
import sys
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path

from PIL import Image, UnidentifiedImageError


PRIORITY = {
    "manual_confirmed_by_user": 0,
    "exact_name": 1,
    "name_alias": 2,
    "base_name_plus_variant": 3,
}


@dataclass(frozen=True)
class MappedRow:
    product_slug: str
    image_path: str
    match_method: str


def parse_args() -> argparse.Namespace:
    project_root = Path(__file__).resolve().parents[1]
    default_csv = (
        project_root / "docs" / "photo_audit_2026-02-17" / "photo_audit_all_in_one.csv"
    )
    default_source = project_root / "AUSHEN Product Photos"
    default_output = project_root / "public" / "product-photos"
    default_generated = project_root / "src" / "data" / "product_images.generated.ts"
    default_summary = (
        project_root / "docs" / "photo_audit_2026-02-17" / "summary_after_publish.txt"
    )

    parser = argparse.ArgumentParser(description="Prepare product photos for web use.")
    parser.add_argument("--audit-csv", type=Path, default=default_csv)
    parser.add_argument("--source-root", type=Path, default=default_source)
    parser.add_argument("--output-dir", type=Path, default=default_output)
    parser.add_argument("--generated-ts", type=Path, default=default_generated)
    parser.add_argument("--summary-file", type=Path, default=default_summary)
    parser.add_argument("--max-side", type=int, default=1600)
    parser.add_argument("--quality", type=int, default=80)
    return parser.parse_args()


def load_mapped_rows(csv_path: Path) -> list[MappedRow]:
    rows: list[MappedRow] = []
    with csv_path.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        required = {"status", "product_slug", "image_path", "match_method"}
        missing_cols = required - set(reader.fieldnames or [])
        if missing_cols:
            raise ValueError(f"CSV missing required columns: {sorted(missing_cols)}")

        for line in reader:
            if (line.get("status") or "").strip() != "mapped":
                continue
            slug = (line.get("product_slug") or "").strip()
            image_path = (line.get("image_path") or "").strip()
            match_method = (line.get("match_method") or "").strip()
            if not slug or not image_path:
                continue
            rows.append(MappedRow(product_slug=slug, image_path=image_path, match_method=match_method))
    return rows


def row_sort_key(row: MappedRow) -> tuple[int, str]:
    return (PRIORITY.get(row.match_method, 999), row.image_path.lower())


def verify_sources(source_root: Path, mapped_rows: list[MappedRow]) -> list[str]:
    missing: list[str] = []
    for row in mapped_rows:
        src = source_root / row.image_path
        if not src.exists() or not src.is_file():
            missing.append(row.image_path)
    return sorted(set(missing))


def to_webp(source_path: Path, target_path: Path, max_side: int, quality: int) -> None:
    target_path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with Image.open(source_path) as image:
            image = image.convert("RGB")
            width, height = image.size
            longer_side = max(width, height)
            if longer_side > max_side:
                scale = max_side / float(longer_side)
                resized = (max(1, int(width * scale)), max(1, int(height * scale)))
                image = image.resize(resized, Image.Resampling.LANCZOS)
            image.save(target_path, format="WEBP", quality=quality, method=6)
    except UnidentifiedImageError as exc:
        raise RuntimeError(f"Cannot parse image: {source_path}") from exc


def write_generated_ts(
    generated_ts: Path,
    galleries: dict[str, list[str]],
    covers: dict[str, str],
) -> None:
    ordered_galleries = {k: galleries[k] for k in sorted(galleries)}
    ordered_covers = {k: covers[k] for k in sorted(covers)}
    content = (
        "// This file is auto-generated by scripts/prepare-product-photos.py. Do not edit.\n\n"
        f"export const PRODUCT_IMAGE_GALLERIES: Record<string, string[]> = {json.dumps(ordered_galleries, indent=2)};\n\n"
        f"export const PRODUCT_COVER_IMAGES: Record<string, string> = {json.dumps(ordered_covers, indent=2)};\n"
    )
    generated_ts.parent.mkdir(parents=True, exist_ok=True)
    generated_ts.write_text(content, encoding="utf-8")


def write_summary(
    summary_path: Path,
    mapped_rows_count: int,
    successful_webp_count: int,
    missing_sources: list[str],
    covered_products_count: int,
) -> None:
    lines = [
        f"mapped_rows_count={mapped_rows_count}",
        f"successful_webp_count={successful_webp_count}",
        f"missing_source_count={len(missing_sources)}",
        f"covered_products_count={covered_products_count}",
    ]
    if missing_sources:
        lines.append("missing_sources=")
        lines.extend(f"- {path}" for path in missing_sources)
    summary_path.parent.mkdir(parents=True, exist_ok=True)
    summary_path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def main() -> int:
    args = parse_args()

    mapped_rows = load_mapped_rows(args.audit_csv)
    grouped: dict[str, list[MappedRow]] = defaultdict(list)
    for row in mapped_rows:
        grouped[row.product_slug].append(row)
    for slug in grouped:
        grouped[slug].sort(key=row_sort_key)

    missing_sources = verify_sources(args.source_root, mapped_rows)
    if missing_sources:
        write_summary(
            summary_path=args.summary_file,
            mapped_rows_count=len(mapped_rows),
            successful_webp_count=0,
            missing_sources=missing_sources,
            covered_products_count=0,
        )
        print("Missing source images detected. See summary file for details.", file=sys.stderr)
        return 1

    if args.output_dir.exists():
        shutil.rmtree(args.output_dir)
    args.output_dir.mkdir(parents=True, exist_ok=True)

    galleries: dict[str, list[str]] = {}
    covers: dict[str, str] = {}
    successful_webp_count = 0

    for slug in sorted(grouped):
        urls: list[str] = []
        output_index = 1
        for row in grouped[slug]:
            source_path = args.source_root / row.image_path
            target_name = f"{slug}-{output_index:02d}.webp"
            target_path = args.output_dir / target_name
            to_webp(
                source_path=source_path,
                target_path=target_path,
                max_side=args.max_side,
                quality=args.quality,
            )
            urls.append(f"/product-photos/{target_name}")
            successful_webp_count += 1
            output_index += 1

        if urls:
            galleries[slug] = urls
            covers[slug] = urls[0]

    write_generated_ts(
        generated_ts=args.generated_ts,
        galleries=galleries,
        covers=covers,
    )
    write_summary(
        summary_path=args.summary_file,
        mapped_rows_count=len(mapped_rows),
        successful_webp_count=successful_webp_count,
        missing_sources=missing_sources,
        covered_products_count=len(galleries),
    )

    print(f"mapped_rows={len(mapped_rows)}")
    print(f"successful_webp={successful_webp_count}")
    print(f"covered_products={len(galleries)}")
    print(f"generated_ts={args.generated_ts}")
    print(f"output_dir={args.output_dir}")
    print(f"summary_file={args.summary_file}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
